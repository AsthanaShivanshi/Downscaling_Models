{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d01217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvNew/lib/python3.10/site-packages/pyproj/network.py:59: UserWarning: pyproj unable to set PROJ database path.\n",
      "  _set_context_ca_bundle_path(ca_bundle_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "os.environ[\"BASE_DIR\"] = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling\"\n",
    "BASE_DIR = os.environ[\"BASE_DIR\"]\n",
    "import json\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7435896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../../Scripts/Functions/Climate_Indices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de479224",
   "metadata": {},
   "source": [
    "Loading the saved quick check trained model from Downscaling_Models/UNet_Deterministic_training_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1cf7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(BASE_DIR,\"sasthana/Downscaling/Downscaling_Models/models_UNet/UNet_Deterministic_Training_Dataset_Optim_Weights/training_model_huber_weights.pth\")\n",
    "training_checkpoint = torch.load(model_path, map_location=torch.device('cpu'))  # Moving model to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c587ea78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "#Checking the parameters and keys\n",
    "print(type(training_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a15f4478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\n",
      "model_state_dict\n",
      "optimizer_state_dict\n",
      "loss\n"
     ]
    }
   ],
   "source": [
    "#Checking all model parameters \n",
    "for key in training_checkpoint.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c53c8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing UNet class from Unet.py\n",
    "sys.path.append(os.path.join(BASE_DIR, \"sasthana/Downscaling/Downscaling_Models/models_UNet/UNet_Deterministic_Training_Dataset_Optim_Weights\"))\n",
    "from UNet import UNet #Importing Unet class\n",
    "from Downscaling_Dataset_Prep import DownscalingDataset #for creating paired frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8386844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b06b1c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (Encoder1): Encoder_Block(\n",
       "    (conv): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (Encoder2): Encoder_Block(\n",
       "    (conv): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (Encoder3): Encoder_Block(\n",
       "    (conv): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (Encoder4): Encoder_Block(\n",
       "    (conv): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (bottleneck): DoubleConv(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Decoder1): Decoder_Block(\n",
       "    (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (Decoder2): Decoder_Block(\n",
       "    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (Decoder3): Decoder_Block(\n",
       "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (Decoder4): Decoder_Block(\n",
       "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outputs): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After loading your model:\n",
    "model_instance = UNet(in_channels=5, out_channels=4)\n",
    "model_instance.load_state_dict(training_checkpoint[\"model_state_dict\"])\n",
    "model_instance.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fdbd09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output layer weights (shape torch.Size([4, 64, 1, 1])):\n",
      "tensor([[[[ 3.2267e-01]],\n",
      "\n",
      "         [[-5.5676e-01]],\n",
      "\n",
      "         [[ 7.7789e-01]],\n",
      "\n",
      "         [[ 3.1836e-01]],\n",
      "\n",
      "         [[-1.3968e-01]],\n",
      "\n",
      "         [[-1.1406e-02]],\n",
      "\n",
      "         [[ 1.9246e-01]],\n",
      "\n",
      "         [[ 3.6610e-01]],\n",
      "\n",
      "         [[-1.2950e-01]],\n",
      "\n",
      "         [[-3.6183e-01]],\n",
      "\n",
      "         [[-5.2515e-03]],\n",
      "\n",
      "         [[-1.5317e+00]],\n",
      "\n",
      "         [[ 3.9954e-01]],\n",
      "\n",
      "         [[-2.7019e-01]],\n",
      "\n",
      "         [[ 1.1087e-02]],\n",
      "\n",
      "         [[ 1.1277e+00]],\n",
      "\n",
      "         [[ 1.2120e-01]],\n",
      "\n",
      "         [[-1.3975e-01]],\n",
      "\n",
      "         [[-2.7851e-01]],\n",
      "\n",
      "         [[-1.9020e-01]],\n",
      "\n",
      "         [[ 2.6497e-01]],\n",
      "\n",
      "         [[ 1.7840e-02]],\n",
      "\n",
      "         [[-4.9229e-01]],\n",
      "\n",
      "         [[-1.1833e+00]],\n",
      "\n",
      "         [[-1.0326e+00]],\n",
      "\n",
      "         [[-5.6484e-01]],\n",
      "\n",
      "         [[ 2.1222e-01]],\n",
      "\n",
      "         [[-4.3480e-01]],\n",
      "\n",
      "         [[-2.2454e-01]],\n",
      "\n",
      "         [[ 1.3742e-02]],\n",
      "\n",
      "         [[ 8.5275e-01]],\n",
      "\n",
      "         [[ 7.5718e-01]],\n",
      "\n",
      "         [[ 1.0743e-03]],\n",
      "\n",
      "         [[-7.6904e-02]],\n",
      "\n",
      "         [[-7.3713e-01]],\n",
      "\n",
      "         [[-7.8225e-03]],\n",
      "\n",
      "         [[ 5.6275e-01]],\n",
      "\n",
      "         [[ 8.0946e-03]],\n",
      "\n",
      "         [[ 6.7987e-02]],\n",
      "\n",
      "         [[-1.4067e-01]],\n",
      "\n",
      "         [[ 5.3093e-03]],\n",
      "\n",
      "         [[ 2.3327e-02]],\n",
      "\n",
      "         [[ 4.9802e-02]],\n",
      "\n",
      "         [[ 9.4571e-01]],\n",
      "\n",
      "         [[ 5.4378e-01]],\n",
      "\n",
      "         [[ 9.4546e-01]],\n",
      "\n",
      "         [[ 3.2665e-01]],\n",
      "\n",
      "         [[-1.5484e-01]],\n",
      "\n",
      "         [[-8.8630e-01]],\n",
      "\n",
      "         [[-1.1387e-02]],\n",
      "\n",
      "         [[-2.0455e+00]],\n",
      "\n",
      "         [[-1.3568e+00]],\n",
      "\n",
      "         [[ 2.8324e-02]],\n",
      "\n",
      "         [[ 1.4825e-01]],\n",
      "\n",
      "         [[-5.7586e-02]],\n",
      "\n",
      "         [[-1.3087e+00]],\n",
      "\n",
      "         [[-1.5283e+00]],\n",
      "\n",
      "         [[ 7.5673e-01]],\n",
      "\n",
      "         [[ 8.2146e-02]],\n",
      "\n",
      "         [[-2.4390e-01]],\n",
      "\n",
      "         [[-1.2239e-01]],\n",
      "\n",
      "         [[ 1.0856e+00]],\n",
      "\n",
      "         [[ 1.3965e+00]],\n",
      "\n",
      "         [[ 3.2246e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.2942e-01]],\n",
      "\n",
      "         [[ 1.2705e+00]],\n",
      "\n",
      "         [[ 2.5144e-02]],\n",
      "\n",
      "         [[ 4.6841e-01]],\n",
      "\n",
      "         [[-7.9667e-01]],\n",
      "\n",
      "         [[-5.2550e-01]],\n",
      "\n",
      "         [[-2.6736e-02]],\n",
      "\n",
      "         [[-3.1450e-01]],\n",
      "\n",
      "         [[-3.2972e-01]],\n",
      "\n",
      "         [[-3.1772e-01]],\n",
      "\n",
      "         [[ 5.7869e-01]],\n",
      "\n",
      "         [[ 2.7962e-02]],\n",
      "\n",
      "         [[-2.8579e-01]],\n",
      "\n",
      "         [[ 4.9442e-01]],\n",
      "\n",
      "         [[ 2.7801e-02]],\n",
      "\n",
      "         [[ 1.6451e+00]],\n",
      "\n",
      "         [[ 5.1184e-01]],\n",
      "\n",
      "         [[-2.2414e+00]],\n",
      "\n",
      "         [[-1.3329e+00]],\n",
      "\n",
      "         [[ 2.9786e-01]],\n",
      "\n",
      "         [[ 9.9484e-01]],\n",
      "\n",
      "         [[-7.1193e-01]],\n",
      "\n",
      "         [[-1.0589e-01]],\n",
      "\n",
      "         [[-1.0231e+00]],\n",
      "\n",
      "         [[ 8.0514e-01]],\n",
      "\n",
      "         [[ 2.8797e-01]],\n",
      "\n",
      "         [[ 5.0365e-01]],\n",
      "\n",
      "         [[ 6.7488e-01]],\n",
      "\n",
      "         [[-7.3390e-01]],\n",
      "\n",
      "         [[-3.2676e-03]],\n",
      "\n",
      "         [[-5.0770e-01]],\n",
      "\n",
      "         [[-1.1520e-01]],\n",
      "\n",
      "         [[ 4.0335e-02]],\n",
      "\n",
      "         [[ 1.0010e+00]],\n",
      "\n",
      "         [[ 6.9735e-01]],\n",
      "\n",
      "         [[-5.1052e-02]],\n",
      "\n",
      "         [[-5.7840e-01]],\n",
      "\n",
      "         [[ 3.5188e-01]],\n",
      "\n",
      "         [[ 1.9793e-01]],\n",
      "\n",
      "         [[-2.5646e-02]],\n",
      "\n",
      "         [[ 2.0325e-01]],\n",
      "\n",
      "         [[-4.0134e-01]],\n",
      "\n",
      "         [[-7.8533e-01]],\n",
      "\n",
      "         [[-9.8305e-03]],\n",
      "\n",
      "         [[ 1.4761e-01]],\n",
      "\n",
      "         [[-6.4137e-02]],\n",
      "\n",
      "         [[ 9.0816e-03]],\n",
      "\n",
      "         [[-2.6970e-01]],\n",
      "\n",
      "         [[ 5.6665e-01]],\n",
      "\n",
      "         [[ 9.8360e-01]],\n",
      "\n",
      "         [[ 1.0373e-01]],\n",
      "\n",
      "         [[ 9.8336e-01]],\n",
      "\n",
      "         [[-5.2656e-01]],\n",
      "\n",
      "         [[-1.0730e-01]],\n",
      "\n",
      "         [[-1.1380e+00]],\n",
      "\n",
      "         [[ 7.0555e-01]],\n",
      "\n",
      "         [[-2.8652e-02]],\n",
      "\n",
      "         [[ 5.7939e-01]],\n",
      "\n",
      "         [[ 2.1494e-01]],\n",
      "\n",
      "         [[ 2.4499e-01]],\n",
      "\n",
      "         [[-6.9792e-01]],\n",
      "\n",
      "         [[-2.7682e-01]],\n",
      "\n",
      "         [[-1.3964e+00]],\n",
      "\n",
      "         [[ 5.3094e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.4267e-01]],\n",
      "\n",
      "         [[ 1.1871e+00]],\n",
      "\n",
      "         [[ 2.6306e-01]],\n",
      "\n",
      "         [[ 8.6815e-02]],\n",
      "\n",
      "         [[ 9.7458e-01]],\n",
      "\n",
      "         [[ 1.0668e+00]],\n",
      "\n",
      "         [[ 8.2307e-01]],\n",
      "\n",
      "         [[ 4.9243e-02]],\n",
      "\n",
      "         [[-2.3413e-01]],\n",
      "\n",
      "         [[-3.2429e-01]],\n",
      "\n",
      "         [[ 3.3305e-01]],\n",
      "\n",
      "         [[-3.7733e-01]],\n",
      "\n",
      "         [[-1.7923e-01]],\n",
      "\n",
      "         [[-6.7431e-01]],\n",
      "\n",
      "         [[-1.1054e+00]],\n",
      "\n",
      "         [[-6.1064e-01]],\n",
      "\n",
      "         [[ 9.4021e-01]],\n",
      "\n",
      "         [[-3.2865e-01]],\n",
      "\n",
      "         [[-5.3203e-01]],\n",
      "\n",
      "         [[-3.1957e-01]],\n",
      "\n",
      "         [[-4.2038e-01]],\n",
      "\n",
      "         [[-1.2881e+00]],\n",
      "\n",
      "         [[-4.2695e-01]],\n",
      "\n",
      "         [[ 2.9459e-01]],\n",
      "\n",
      "         [[ 2.6715e-01]],\n",
      "\n",
      "         [[ 6.4188e-01]],\n",
      "\n",
      "         [[-3.1176e-01]],\n",
      "\n",
      "         [[ 7.0041e-01]],\n",
      "\n",
      "         [[ 3.2049e-01]],\n",
      "\n",
      "         [[ 6.6160e-01]],\n",
      "\n",
      "         [[ 6.0047e-01]],\n",
      "\n",
      "         [[-6.8203e-01]],\n",
      "\n",
      "         [[-5.9477e-01]],\n",
      "\n",
      "         [[ 4.3774e-01]],\n",
      "\n",
      "         [[ 6.1066e-01]],\n",
      "\n",
      "         [[-1.1612e+00]],\n",
      "\n",
      "         [[-1.0321e+00]],\n",
      "\n",
      "         [[ 4.4254e-01]],\n",
      "\n",
      "         [[-6.9761e-01]],\n",
      "\n",
      "         [[ 1.1817e+00]],\n",
      "\n",
      "         [[ 8.4588e-01]],\n",
      "\n",
      "         [[-5.2103e-01]],\n",
      "\n",
      "         [[ 8.4035e-01]],\n",
      "\n",
      "         [[ 2.6912e-01]],\n",
      "\n",
      "         [[ 1.5202e-01]],\n",
      "\n",
      "         [[-1.5054e-01]],\n",
      "\n",
      "         [[-8.2035e-01]],\n",
      "\n",
      "         [[-1.0094e-01]],\n",
      "\n",
      "         [[ 3.6120e-01]],\n",
      "\n",
      "         [[-2.4620e-01]],\n",
      "\n",
      "         [[-2.9338e-01]],\n",
      "\n",
      "         [[-3.6053e-02]],\n",
      "\n",
      "         [[-5.0242e-01]],\n",
      "\n",
      "         [[ 3.7926e-01]],\n",
      "\n",
      "         [[-1.7060e-01]],\n",
      "\n",
      "         [[-6.5801e-01]],\n",
      "\n",
      "         [[-7.5252e-01]],\n",
      "\n",
      "         [[ 7.5990e-01]],\n",
      "\n",
      "         [[ 1.7378e-01]],\n",
      "\n",
      "         [[ 2.2654e-01]],\n",
      "\n",
      "         [[ 7.9747e-01]],\n",
      "\n",
      "         [[ 3.6010e-01]],\n",
      "\n",
      "         [[ 3.3386e-01]],\n",
      "\n",
      "         [[ 1.4429e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7344e-01]],\n",
      "\n",
      "         [[ 7.7745e-01]],\n",
      "\n",
      "         [[ 5.2056e-01]],\n",
      "\n",
      "         [[ 1.1091e-02]],\n",
      "\n",
      "         [[ 1.6921e-01]],\n",
      "\n",
      "         [[-1.5791e+00]],\n",
      "\n",
      "         [[-6.1337e-01]],\n",
      "\n",
      "         [[ 3.3859e-02]],\n",
      "\n",
      "         [[ 8.3700e-01]],\n",
      "\n",
      "         [[-6.2493e-01]],\n",
      "\n",
      "         [[ 6.4542e-01]],\n",
      "\n",
      "         [[ 4.9527e-01]],\n",
      "\n",
      "         [[-4.8898e-01]],\n",
      "\n",
      "         [[ 5.2102e-03]],\n",
      "\n",
      "         [[ 4.7579e-01]],\n",
      "\n",
      "         [[ 7.5741e-02]],\n",
      "\n",
      "         [[ 8.5879e-01]],\n",
      "\n",
      "         [[ 5.3125e-01]],\n",
      "\n",
      "         [[-1.3274e-01]],\n",
      "\n",
      "         [[ 1.7148e-01]],\n",
      "\n",
      "         [[ 1.0795e+00]],\n",
      "\n",
      "         [[ 4.1010e-02]],\n",
      "\n",
      "         [[-1.2288e+00]],\n",
      "\n",
      "         [[ 8.6368e-01]],\n",
      "\n",
      "         [[ 3.7279e-02]],\n",
      "\n",
      "         [[ 3.5740e-02]],\n",
      "\n",
      "         [[ 3.5802e-01]],\n",
      "\n",
      "         [[ 1.1663e+00]],\n",
      "\n",
      "         [[-2.7438e-01]],\n",
      "\n",
      "         [[ 3.3962e-01]],\n",
      "\n",
      "         [[-2.3271e-01]],\n",
      "\n",
      "         [[-5.9919e-01]],\n",
      "\n",
      "         [[ 4.5490e-01]],\n",
      "\n",
      "         [[ 1.1888e+00]],\n",
      "\n",
      "         [[-1.6477e-01]],\n",
      "\n",
      "         [[ 7.0278e-01]],\n",
      "\n",
      "         [[-3.0416e-01]],\n",
      "\n",
      "         [[ 5.2950e-01]],\n",
      "\n",
      "         [[-4.9383e-01]],\n",
      "\n",
      "         [[ 2.7272e-01]],\n",
      "\n",
      "         [[-3.1618e-01]],\n",
      "\n",
      "         [[-4.9356e-01]],\n",
      "\n",
      "         [[-9.6633e-01]],\n",
      "\n",
      "         [[ 4.0851e-01]],\n",
      "\n",
      "         [[-3.8617e-01]],\n",
      "\n",
      "         [[ 2.1783e-01]],\n",
      "\n",
      "         [[ 5.3661e-01]],\n",
      "\n",
      "         [[ 5.4164e-01]],\n",
      "\n",
      "         [[ 5.1961e-01]],\n",
      "\n",
      "         [[ 2.5118e-01]],\n",
      "\n",
      "         [[-5.7104e-01]],\n",
      "\n",
      "         [[-6.8418e-01]],\n",
      "\n",
      "         [[-4.5986e-01]],\n",
      "\n",
      "         [[-2.2594e-01]],\n",
      "\n",
      "         [[-1.4713e-01]],\n",
      "\n",
      "         [[-8.7316e-01]],\n",
      "\n",
      "         [[ 5.3544e-01]],\n",
      "\n",
      "         [[ 1.2537e-01]],\n",
      "\n",
      "         [[-3.8934e-01]],\n",
      "\n",
      "         [[-3.7047e-01]],\n",
      "\n",
      "         [[ 3.8670e-01]],\n",
      "\n",
      "         [[ 4.6893e-02]],\n",
      "\n",
      "         [[ 1.0515e+00]],\n",
      "\n",
      "         [[ 6.1630e-01]]]])\n",
      "Final output layer bias (shape torch.Size([4])):\n",
      "tensor([-0.0089, -0.0081,  0.0030,  0.0087])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_instance.named_parameters():\n",
    "    if name == \"outputs.weight\":\n",
    "        print(f\"Final output layer weights (shape {param.shape}):\")\n",
    "        print(param.data)\n",
    "    if name == \"outputs.bias\":\n",
    "        print(f\"Final output layer bias (shape {param.shape}):\")\n",
    "        print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b7315a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaled datasets for test set (2011-2020) :loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ed96f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_input = xr.open_dataset(os.path.join(BASE_DIR, \"sasthana\", \"Downscaling\", \"Downscaling_Models\", \"Training_Chronological_Dataset\", \"RhiresD_input_test_chronological_scaled.nc\"))\n",
    "temp_input = xr.open_dataset(os.path.join(BASE_DIR, \"sasthana\", \"Downscaling\", \"Downscaling_Models\", \"Training_Chronological_Dataset\", \"TabsD_input_test_chronological_scaled.nc\"))\n",
    "tmin_input= xr.open_dataset(os.path.join(BASE_DIR, \"sasthana\", \"Downscaling\", \"Downscaling_Models\", \"Training_Chronological_Dataset\", \"TminD_input_test_chronological_scaled.nc\"))\n",
    "tmax_input= xr.open_dataset(os.path.join(BASE_DIR, \"sasthana\", \"Downscaling\", \"Downscaling_Models\", \"Training_Chronological_Dataset\", \"TmaxD_input_test_chronological_scaled.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20ee32b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_target = xr.open_dataset(os.path.join(BASE_DIR, \"sasthana\", \"Downscaling\", \"Downscaling_Models\", \"Training_Chronological_Dataset\", \"RhiresD_target_test_chronological_scaled.nc\"))\n",
    "temp_target = xr.open_dataset(os.path.join(BASE_DIR, \"sasthana\", \"Downscaling\", \"Downscaling_Models\", \"Training_Chronological_Dataset\", \"TabsD_target_test_chronological_scaled.nc\"))\n",
    "tmin_target = xr.open_dataset(os.path.join(BASE_DIR, \"sasthana\", \"Downscaling\", \"Downscaling_Models\", \"Training_Chronological_Dataset\", \"TminD_target_test_chronological_scaled.nc\"))\n",
    "tmax_target = xr.open_dataset(os.path.join(BASE_DIR, \"sasthana\", \"Downscaling\", \"Downscaling_Models\", \"Training_Chronological_Dataset\", \"TmaxD_target_test_chronological_scaled.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f45e4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the paired feature-target dataset; first loading individual and coverting them into images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dbd20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config used for training \n",
    "config_path = os.path.join(BASE_DIR, \"sasthana/Downscaling/Downscaling_Models/models_UNet/UNet_Deterministic_Training_Dataset_Optim_Weights/config.yaml\")\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "871ecfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elevation\n",
    "elevation_path = os.path.join(BASE_DIR, \"sasthana/Downscaling/Downscaling_Models/elevation.tif\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5294e91",
   "metadata": {},
   "source": [
    "merging DS before creating pairs,,,,wont work for individual files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6847b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded elevation from /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling_Models/elevation.tif, shape: (255, 387)\n"
     ]
    }
   ],
   "source": [
    "inputs_merged = xr.merge([precip_input, temp_input, tmin_input, tmax_input])\n",
    "targets_merged = xr.merge([precip_target, temp_target, tmin_target, tmax_target])\n",
    "\n",
    "ds = DownscalingDataset(inputs_merged, targets_merged, config, elevation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "718f9d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: 3653 samples\n"
     ]
    }
   ],
   "source": [
    "#Checking shape of the ds instance \n",
    "print(f\"Dataset shape: {ds.__len__()} samples\") #Number of samples in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdc42b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image shape: torch.Size([5, 240, 370])\n",
      "Target image shape: torch.Size([4, 240, 370])\n"
     ]
    }
   ],
   "source": [
    "#Checking shape of a random sample\n",
    "input_img,target_img= ds[15] #14 th sample\n",
    "print(f\"Input image shape: {input_img.shape}\")\n",
    "print(f\"Target image shape: {target_img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "504d7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "paired_ds = DataLoader(ds, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3336da11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 240, 370])\n",
      "torch.Size([1, 4, 240, 370])\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in paired_ds:\n",
    "    print(input_batch.shape)  # (1, 5, H, W)\n",
    "    print(target_batch.shape) # (1, 4, H, W)\n",
    "    break  # iterating once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30d001ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx= 2008\n",
    "input_img, target_img =ds[idx]\n",
    "input_img= input_img.unsqueeze(0) # Adding batch dimension\n",
    "date=str(inputs_merged.time.values[idx]) #What date?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eabc5ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance.eval()\n",
    "with torch.no_grad():\n",
    "    pred_img = model_instance(input_img).squeeze(0).cpu().numpy()  \n",
    "target_img = target_img.cpu().numpy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8be976b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descale_precip(x, min_val, max_val):\n",
    "    return x * (max_val - min_val) + min_val\n",
    "\n",
    "def descale_temp(x, mean, std):\n",
    "    return x * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d57c416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling params loading from the .json files\n",
    "scaling_dir = os.path.join(BASE_DIR, \"sasthana/Downscaling/Downscaling_Models/Training_Chronological_Dataset\")\n",
    "rhiresd_params = json.load(open(os.path.join(scaling_dir, \"RhiresD_scaling_params_chronological.json\")))\n",
    "tabsd_params   = json.load(open(os.path.join(scaling_dir, \"TabsD_scaling_params_chronological.json\")))\n",
    "tmind_params   = json.load(open(os.path.join(scaling_dir, \"TminD_scaling_params_chronological.json\")))\n",
    "tmaxd_params   = json.load(open(os.path.join(scaling_dir, \"TmaxD_scaling_params_chronological.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5f9bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img_denorm = np.empty_like(pred_img)\n",
    "target_img_denorm = np.empty_like(target_img)\n",
    "\n",
    "pred_img_denorm[0] = descale_precip(pred_img[0], rhiresd_params[\"min\"], rhiresd_params[\"max\"])\n",
    "pred_img_denorm[1] = descale_temp(pred_img[1], tabsd_params[\"mean\"], tabsd_params[\"std\"])\n",
    "pred_img_denorm[2] = descale_temp(pred_img[2], tmind_params[\"mean\"], tmind_params[\"std\"])\n",
    "pred_img_denorm[3] = descale_temp(pred_img[3], tmaxd_params[\"mean\"], tmaxd_params[\"std\"])\n",
    "\n",
    "target_img_denorm[0] = descale_precip(target_img[0], rhiresd_params[\"min\"], rhiresd_params[\"max\"])\n",
    "target_img_denorm[1] = descale_temp(target_img[1], tabsd_params[\"mean\"], tabsd_params[\"std\"])\n",
    "target_img_denorm[2] = descale_temp(target_img[2], tmind_params[\"mean\"], tmind_params[\"std\"])\n",
    "target_img_denorm[3] = descale_temp(target_img[3], tmaxd_params[\"mean\"], tmaxd_params[\"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2873fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading coarsened files \n",
    "# Load coarse bicubic files\n",
    "coarse_files = {\n",
    "    \"RhiresD\": BASE_DIR+\"/sasthana/Downscaling/Downscaling_Models/Training_Chronological_Dataset/RhiresD_step2_coarse.nc\",\n",
    "    \"TabsD\":   BASE_DIR+\"/sasthana/Downscaling/Downscaling_Models/Training_Chronological_Dataset/TabsD_step2_coarse.nc\",\n",
    "    \"TminD\":   BASE_DIR+\"/sasthana/Downscaling/Downscaling_Models/Training_Chronological_Dataset/TminD_step2_coarse.nc\",\n",
    "    \"TmaxD\":   BASE_DIR+\"/sasthana/Downscaling/Downscaling_Models/Training_Chronological_Dataset/TmaxD_step2_coarse.nc\"\n",
    "}\n",
    "coarse_ds = {var: xr.open_dataset(path) for var, path in coarse_files.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68805c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_val = inputs_merged.time.values[idx]\n",
    "lat = inputs_merged.lat.values\n",
    "lon = inputs_merged.lon.values\n",
    "var_names = [\"RhiresD\", \"TabsD\", \"TminD\", \"TmaxD\"]\n",
    "# Define fixed colorbar limits for each variable\n",
    "vmin_dict = {\"RhiresD\": 0, \"TabsD\": -25, \"TminD\": -20, \"TmaxD\": -10}\n",
    "vmax_dict = {\"RhiresD\": 50, \"TabsD\": 25, \"TminD\": 20, \"TmaxD\": 30}\n",
    "\n",
    "swiss_extent = [5.9, 10.5, 45.7, 47.9]  \n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(18, 18), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "input_img = input_img.squeeze(0)  \n",
    "for i, var in enumerate(var_names):\n",
    "    # COARSE IMAGE\n",
    "    # Get coarse bicubic image for this variable\n",
    "    coarse_var_name=var\n",
    "    coarse_img = coarse_ds[var][var].sel(time=time_val).values\n",
    "    coarse_lat= coarse_ds[var].lat.values\n",
    "    coarse_lon= coarse_ds[var].lon.values\n",
    "\n",
    "    #Input image : bicubic\n",
    "    input_img_denorm = None\n",
    "    if var == \"RhiresD\":\n",
    "        input_img_denorm = descale_precip(input_img[0].cpu().numpy(), rhiresd_params[\"min\"], rhiresd_params[\"max\"])\n",
    "    elif var == \"TabsD\":\n",
    "        input_img_denorm = descale_temp(input_img[1].cpu().numpy(), tabsd_params[\"mean\"], tabsd_params[\"std\"])\n",
    "    elif var == \"TminD\":\n",
    "        input_img_denorm = descale_temp(input_img[2].cpu().numpy(), tmind_params[\"mean\"], tmind_params[\"std\"])\n",
    "    elif var == \"TmaxD\":\n",
    "        input_img_denorm = descale_temp(input_img[3].cpu().numpy(), tmaxd_params[\"mean\"], tmaxd_params[\"std\"])\n",
    "\n",
    "    vmin = vmin_dict[var]\n",
    "    vmax = vmax_dict[var]\n",
    "\n",
    "    #Plotting coarse image\n",
    "    # Plotting coarse image\n",
    "    ax = axes[i, 0]\n",
    "    im = ax.pcolormesh(coarse_lon, coarse_lat, coarse_img, cmap='coolwarm', vmin=vmin, vmax=vmax, shading='auto', transform=ccrs.PlateCarree())\n",
    "    ax.set_title(f\"Coarse Bicubic {var}\")\n",
    "    ax.set_extent(swiss_extent, crs=ccrs.PlateCarree())\n",
    "    ax.coastlines(resolution='10m')\n",
    "    ax.add_feature(cfeature.BORDERS)\n",
    "    fig.colorbar(im, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "\n",
    "    # Input\n",
    "    ax = axes[i, 1]\n",
    "    im = ax.pcolormesh(lon, lat, input_img_denorm, cmap='coolwarm', vmin=vmin, vmax=vmax, shading='auto', transform=ccrs.PlateCarree())\n",
    "    ax.set_title(f\"Input {var}\")\n",
    "    ax.set_extent(swiss_extent, crs=ccrs.PlateCarree())\n",
    "    ax.coastlines(resolution='10m')\n",
    "    ax.add_feature(cfeature.BORDERS)\n",
    "    fig.colorbar(im, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "    # Target\n",
    "    ax = axes[i, 2]\n",
    "    im = ax.pcolormesh(lon, lat, target_img_denorm[i], cmap='coolwarm', vmin=vmin, vmax=vmax, shading='auto', transform=ccrs.PlateCarree())\n",
    "    ax.set_title(f\"Target {var}\")\n",
    "    ax.set_extent(swiss_extent, crs=ccrs.PlateCarree())\n",
    "    ax.coastlines(resolution='10m')\n",
    "    ax.add_feature(cfeature.BORDERS)\n",
    "    fig.colorbar(im, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "    # Predicted\n",
    "    ax = axes[i, 3]\n",
    "    im = ax.pcolormesh(lon, lat, pred_img_denorm[i], cmap='coolwarm', vmin=vmin, vmax=vmax, shading='auto', transform=ccrs.PlateCarree())\n",
    "    ax.set_title(f\"Predicted {var}\")\n",
    "    ax.set_extent(swiss_extent, crs=ccrs.PlateCarree())\n",
    "    ax.coastlines(resolution='10m')\n",
    "    ax.add_feature(cfeature.BORDERS)\n",
    "    fig.colorbar(im, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "plt.suptitle(f\"Coarse, Inputs(bicubic) , Target(HR) and Predictions from 1971-2020 time series : {date}\", fontsize=14, y=0.95)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(BASE_DIR, \"sasthana\", \"Downscaling\", \"Processing_and_Analysis_Scripts\", \"Outputs\", f\"predictions_{date}.png\"), dpi=1000)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyPythonEnvNew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
