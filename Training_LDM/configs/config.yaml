defaults:
  - paths: paths.yaml

experiment:
  batch_size: 32
  num_workers: 4
  quick_test: false

variables:
  input:
    precip: RhiresD
    temp: TabsD
    temp_min: TminD
    temp_max: TmaxD
  target:
    precip: RhiresD
    temp: TabsD
    temp_min: TminD
    temp_max: TmaxD

preprocessing:
  nan_to_num: true
  nan_value : 0.0

train:
  num_epochs: 200
  checkpoint_path: training_model_huber_weights.pth
  inference_weights_path: training_model_weights_huber_weights.pth
  model_config_path: training_model_config_huber_weights.json
  in_channels: 5
  out_channels: 4
  optimizer: "Adam"
  loss_fn: "huber"
  huber_delta: 0.005
  scheduler: "ReduceLROnPlateau"
  scheduler_mode: "min"
  scheduler_factor: 0.8
  scheduler_patience: 2
  early_stopping_patience: 5
  wandb_project: "LDM_res"
  wandb_run_name: "Training_Dataset"

data:
  train:
    input: ${paths.data.train.input}
    target: ${paths.data.train.target}
  val:
    input: ${paths.data.val.input}
    target: ${paths.data.val.target}
  test:
    input: ${paths.data.test.input}
    target: ${paths.data.test.target}
  static:
    elevation: ${paths.data.static.elevation}


datamodule:
  _target_: Training_LDM.DownscalingDataModule
  train_input: ${data.train.input.precip}
  train_target: ${data.train.target.precip}
  val_input: ${data.val.input.precip}
  val_target: ${data.val.target.precip}
  test_input: ${data.test.input.precip}
  test_target: ${data.test.target.precip}
  elevation: ${data.static.elevation}
  batch_size: ${experiment.batch_size}
  num_workers: ${experiment.num_workers}
  preprocessing:
    variables: ${variables}
    preprocessing: ${preprocessing}

model:
  _target_: Training_LDM.models.ldm_module.LatentDiffusion
  in_channels: ${train.in_channels}
  out_channels: ${train.out_channels}
  optimizer: ${train.optimizer}
  loss_fn: ${train.loss_fn}
  huber_delta: ${train.huber_delta}
