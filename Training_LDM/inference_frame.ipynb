{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5bf3df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") #Parent \n",
    "sys.path.append(\"../..\") #grandparent\n",
    "import torch\n",
    "from models.components.ldm.denoiser import UNetModel\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import config\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c0913a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.components.unet import DownscalingUnetLightning \n",
    "from models.ae_module import AutoencoderKL\n",
    "from models.components.ae import SimpleConvEncoder, SimpleConvDecoder\n",
    "from models.components.ldm.denoiser.ddim import DDIMSampler\n",
    "from models.ldm_module import LatentDiffusion\n",
    "from DownscalingDataModule import DownscalingDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee737fc",
   "metadata": {},
   "source": [
    "Instantiating UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ee86e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_unet = \"trained_ckpts/Training_LDM.models.components.unet.DownscalingUnetLightning_checkpoint.ckpt\"\n",
    "\n",
    "model_UNet = DownscalingUnetLightning(\n",
    "    in_ch=5,  # 4 vars + elevation\n",
    "    out_ch=4,  # 4 output variables\n",
    "    features=[64, 128, 256, 512],\n",
    "    channel_names=[\"precip\", \"temp\", \"temp_min\", \"temp_max\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25b8a04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DownscalingUnetLightning(\n",
       "  (unet): DownscalingUnet(\n",
       "    (e1): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (e2): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (e3): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (e4): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (b): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (d1): DecoderBlock(\n",
       "      (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (d2): DecoderBlock(\n",
       "      (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (d3): DecoderBlock(\n",
       "      (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (d4): DecoderBlock(\n",
       "      (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (outputs): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (loss_fn): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet_state_dict = torch.load(ckpt_unet, map_location=\"cpu\")[\"state_dict\"]\n",
    "model_UNet.load_state_dict(unet_state_dict, strict=False)\n",
    "model_UNet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079fbb63",
   "metadata": {},
   "source": [
    "Instantiating VAE for residual encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fcc53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_vae = \"trained_ckpts/Training_LDM.models.ae_module.AutoencoderKL_checkpoint.ckpt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34788231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Load checkpoint to see the original configuration\n",
    "checkpoint = torch.load(ckpt_vae, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c25181a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling_Models/.micromamba/envs/diffscaler/lib/python3.9/site-packages/torch/serialization.py:869\u001b[0m, in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 869\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m(f\u001b[38;5;241m.\u001b[39mtell())\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m encoder \u001b[38;5;241m=\u001b[39m SimpleConvEncoder(in_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, levels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_ch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, ch_mult\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m decoder \u001b[38;5;241m=\u001b[39m SimpleConvDecoder(in_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, levels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_ch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)  \u001b[38;5;66;03m# Changed from levels=2 to levels=1\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model_VAE \u001b[38;5;241m=\u001b[39m \u001b[43mAutoencoderKL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkl_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m model_VAE\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling_Models/.micromamba/envs/diffscaler/lib/python3.9/site-packages/lightning/pytorch/utilities/model_helpers.py:125\u001b[0m, in \u001b[0;36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be called on an instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling_Models/.micromamba/envs/diffscaler/lib/python3.9/site-packages/lightning/pytorch/core/module.py:1662\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[1;32m   1574\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1575\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1580\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1581\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1582\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1660\u001b[0m \n\u001b[1;32m   1661\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1662\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling_Models/.micromamba/envs/diffscaler/lib/python3.9/site-packages/lightning/pytorch/core/saving.py:63\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m map_location \u001b[38;5;241m=\u001b[39m map_location \u001b[38;5;129;01mor\u001b[39;00m _default_map_location\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[0;32m---> 63\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[1;32m     66\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m _pl_migrate_checkpoint(\n\u001b[1;32m     67\u001b[0m     checkpoint, checkpoint_path\u001b[38;5;241m=\u001b[39m(checkpoint_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint_path, (\u001b[38;5;28mstr\u001b[39m, Path)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     68\u001b[0m )\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling_Models/.micromamba/envs/diffscaler/lib/python3.9/site-packages/lightning/fabric/utilities/cloud_io.py:48\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location, weights_only)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads a checkpoint.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_url, (\u001b[38;5;28mstr\u001b[39m, Path)):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# any sort of BytesIO or similar\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type] # upstream annotation is not correct\u001b[39;49;00m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(path_or_url)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload_state_dict_from_url(\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28mstr\u001b[39m(path_or_url),\n\u001b[1;32m     56\u001b[0m         map_location\u001b[38;5;241m=\u001b[39mmap_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     57\u001b[0m         weights_only\u001b[38;5;241m=\u001b[39mweights_only,\n\u001b[1;32m     58\u001b[0m     )\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling_Models/.micromamba/envs/diffscaler/lib/python3.9/site-packages/torch/serialization.py:1484\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1482\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1486\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1488\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1489\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling_Models/.micromamba/envs/diffscaler/lib/python3.9/site-packages/torch/serialization.py:764\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _open_buffer_writer(name_or_buffer)\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m--> 764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_buffer_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in mode but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling_Models/.micromamba/envs/diffscaler/lib/python3.9/site-packages/torch/serialization.py:749\u001b[0m, in \u001b[0;36m_open_buffer_reader.__init__\u001b[0;34m(self, buffer)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, buffer: IO[\u001b[38;5;28mbytes\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(buffer)\n\u001b[0;32m--> 749\u001b[0m     \u001b[43m_check_seekable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling_Models/.micromamba/envs/diffscaler/lib/python3.9/site-packages/torch/serialization.py:872\u001b[0m, in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (io\u001b[38;5;241m.\u001b[39mUnsupportedOperation, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 872\u001b[0m     \u001b[43mraise_err_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseek\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling_Models/.micromamba/envs/diffscaler/lib/python3.9/site-packages/torch/serialization.py:865\u001b[0m, in \u001b[0;36m_check_seekable.<locals>.raise_err_msg\u001b[0;34m(patterns, e)\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[1;32m    859\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    860\u001b[0m             \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m    861\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. You can only torch.load from a file that is seekable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    862\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please pre-load the data into a buffer like io.BytesIO and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    863\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m try to load from it instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    864\u001b[0m         )\n\u001b[0;32m--> 865\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(msg)\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead."
     ]
    }
   ],
   "source": [
    "encoder = SimpleConvEncoder(in_dim=4, levels=1, min_ch=64, ch_mult=1)\n",
    "decoder = SimpleConvDecoder(in_dim=64, levels=1, min_ch=16)  # Changed from levels=2 to levels=1\n",
    "model_VAE = AutoencoderKL.load_from_checkpoint(\n",
    "    checkpoint,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    kl_weight=0.01,\n",
    "    strict=False \n",
    ")\n",
    "model_VAE.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409c4be6",
   "metadata": {},
   "source": [
    "Latent denoising "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13c59dc",
   "metadata": {},
   "source": [
    "Denoising in latent space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abb89c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_ldm = \"trained_ckpts/LDM_checkpoint.ckpt\"\n",
    "\n",
    "# Denoiser for LDM \n",
    "denoiser = UNetModel(\n",
    "    in_channels=32,  # VAE latent dim\n",
    "    out_channels=32,\n",
    "    model_channels=64,\n",
    "    num_res_blocks=2,\n",
    "    attention_resolutions=[1, 2, 4],\n",
    "    context_ch=None,\n",
    "    channel_mult=[1, 2, 4, 4],\n",
    "    conv_resample=True,\n",
    "    dims=2,\n",
    "    use_fp16=False,\n",
    "    num_heads=4\n",
    ")\n",
    "\n",
    "model_LDM = LatentDiffusion(\n",
    "    denoiser=denoiser,\n",
    "    autoencoder=model_VAE,\n",
    "    timesteps=1000,\n",
    "    beta_schedule=\"linear\",\n",
    "    loss_type=\"l2\",\n",
    "    use_ema=True,\n",
    "    lr=1e-4,\n",
    "    lr_warmup=0,\n",
    "    linear_start=1e-4,\n",
    "    linear_end=2e-2,\n",
    "    cosine_s=8e-3,\n",
    "    parameterization=\"eps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78220863",
   "metadata": {},
   "source": [
    "remapping of keys for overcoming the error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e4073dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldm_ckpt = torch.load(ckpt_ldm, map_location=\"cpu\")\n",
    "remapped_ldm_state_dict = {}\n",
    "for k, v in ldm_ckpt[\"state_dict\"].items():\n",
    "    if k.startswith(\"autoencoder.unet_regr.unet.\"):\n",
    "        new_key = \"autoencoder.unet.\" + k[len(\"autoencoder.unet_regr.unet.\"):]\n",
    "    elif k.startswith(\"autoencoder.unet_regr.\"):\n",
    "        new_key = \"autoencoder.unet.\" + k[len(\"autoencoder.unet_regr.\"):]\n",
    "    else:\n",
    "        new_key = k\n",
    "    remapped_ldm_state_dict[new_key] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65a37748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDiffusion(\n",
       "  (denoiser): UNetModel(\n",
       "    (time_embed): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (input_blocks): ModuleList(\n",
       "      (0): TimestepEmbedSequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1-2): 2 x TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (middle_block): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): Identity()\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): Identity()\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): Identity()\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): Identity()\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (output_blocks): ModuleList(\n",
       "      (0-1): 2 x TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Upsample(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3-4): 2 x TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Upsample(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Upsample(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out): Sequential(\n",
       "      (0): Identity()\n",
       "      (1): SiLU()\n",
       "      (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (autoencoder): AutoencoderKL(\n",
       "    (encoder): SimpleConvEncoder(\n",
       "      (net): Sequential(\n",
       "        (0): ResBlock2D(\n",
       "          (proj): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (conv1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): SiLU()\n",
       "          (act2): SiLU()\n",
       "          (norm1): GroupNorm(1, 4, eps=1e-05, affine=True)\n",
       "          (norm2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (sequence): Sequential(\n",
       "            (0): GroupNorm(1, 4, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "            (4): SiLU()\n",
       "            (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "    )\n",
       "    (decoder): SimpleConvDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): ConvTranspose2d(64, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): ResBlock2D(\n",
       "          (proj): Identity()\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): SiLU()\n",
       "          (act2): SiLU()\n",
       "          (norm1): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "          (norm2): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "          (sequence): Sequential(\n",
       "            (0): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "            (4): SiLU()\n",
       "            (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (3): ResBlock2D(\n",
       "          (proj): Identity()\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): SiLU()\n",
       "          (act2): SiLU()\n",
       "          (norm1): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "          (norm2): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "          (sequence): Sequential(\n",
       "            (0): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "            (4): SiLU()\n",
       "            (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (4): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (to_moments): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (to_decoder): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (denoiser_ema): LitEma()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LDM.load_state_dict(remapped_ldm_state_dict, strict=False)\n",
    "model_LDM.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65521c83",
   "metadata": {},
   "source": [
    "#Inference goes from Unet----VAE----denosiing within VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ba5b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(input_sample, target_sample=None):  \n",
    "    with torch.no_grad():\n",
    "        # Mean pred with unet\n",
    "        unet_prediction = model_UNet(input_sample)\n",
    "        \n",
    "        #Residuals for denoising\n",
    "        if target_sample is not None:\n",
    "            residuals = target_sample - unet_prediction  # (1, 4, H, W)\n",
    "        \n",
    "        #VAE encoding\n",
    "        mean, log_var = model_VAE.encode(residuals)\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        latent = mean + eps * std  # (1, 64, H', W')\n",
    "        \n",
    "        #Denoising using LDM\n",
    "        sampler = DDIMSampler(model_LDM)\n",
    "        shape = latent.shape[1:]\n",
    "        \n",
    "        denoised_latent, _ = sampler.sample(\n",
    "            S=25,\n",
    "            batch_size=1,\n",
    "            shape=shape,\n",
    "            x_T=latent,  # encoded residual latent\n",
    "            eta=0.2,     # stochasticity\n",
    "            verbose=False,\n",
    "            progbar=True\n",
    "        )\n",
    "        \n",
    "        # Decoding to pixel space\n",
    "        refined_residuals = model_VAE.decode(denoised_latent)  # (1, 4, H, W)\n",
    "        \n",
    "        # Unet plus refined residuals\n",
    "        final_prediction = unet_prediction + refined_residuals\n",
    "        \n",
    "        return {\n",
    "            'unet_prediction': unet_prediction,\n",
    "            'original_residuals': residuals,\n",
    "            'latent_encoded': latent,\n",
    "            'denoised_latent': denoised_latent,\n",
    "            'refined_residuals': refined_residuals,\n",
    "            'final_prediction': final_prediction\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bccb9d3",
   "metadata": {},
   "source": [
    "Datasets for dtaamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c70e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_paths = {\n",
    "    'precip': f'{config.DATASETS_TRAINING_DIR}/RhiresD_input_test_chronological_scaled.nc',\n",
    "    'temp': f'{config.DATASETS_TRAINING_DIR}/TabsD_input_test_chronological_scaled.nc',\n",
    "    'temp_min': f'{config.DATASETS_TRAINING_DIR}/TminD_input_test_chronological_scaled.nc',\n",
    "    'temp_max': f'{config.DATASETS_TRAINING_DIR}/TmaxD_input_test_chronological_scaled.nc'\n",
    "}\n",
    "\n",
    "train_target_paths = {\n",
    "    'precip': f'{config.DATASETS_TRAINING_DIR}/RhiresD_target_test_chronological_scaled.nc',\n",
    "    'temp': f'{config.DATASETS_TRAINING_DIR}/TabsD_target_test_chronological_scaled.nc',\n",
    "    'temp_min': f'{config.DATASETS_TRAINING_DIR}/TminD_target_test_chronological_scaled.nc',\n",
    "    'temp_max': f'{config.DATASETS_TRAINING_DIR}/TmaxD_target_test_chronological_scaled.nc'\n",
    "}\n",
    "\n",
    "elevation_path = f'{config.BASE_DIR}/sasthana/Downscaling/Downscaling_Models/elevation.tif'\n",
    "\n",
    "dm = DownscalingDataModule(\n",
    "    train_input=train_input_paths,\n",
    "    train_target=train_target_paths,\n",
    "    elevation=elevation_path,\n",
    "    batch_size=32,\n",
    "    num_workers=4,\n",
    "    preprocessing={\n",
    "        'variables': {\n",
    "            'input': {\n",
    "                'precip': 'RhiresD',\n",
    "                'temp': 'TabsD', \n",
    "                'temp_min': 'TminD',\n",
    "                'temp_max': 'TmaxD'\n",
    "            },\n",
    "            'target': {\n",
    "                'precip': 'RhiresD',\n",
    "                'temp': 'TabsD',\n",
    "                'temp_min': 'TminD', \n",
    "                'temp_max': 'TmaxD'\n",
    "            }\n",
    "        },\n",
    "        'preprocessing': {\n",
    "            'nan_to_num': True,\n",
    "            'nan_value': 0.0\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Setup the data module\n",
    "dm.setup('fit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa90a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dm.train_dataloader()\n",
    "train_batch = next(iter(train_loader))\n",
    "train_inputs, train_targets = train_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a9a1e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 32, 120, 185), eta 0.2\n",
      "Running DDIM Sampling with 25 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 25/25 [26:13<00:00, 62.95s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (370) must match the size of tensor b (740) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m input_sample \u001b[38;5;241m=\u001b[39m train_inputs[idx]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# (1, 5, H, W)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m target_sample \u001b[38;5;241m=\u001b[39m train_targets[idx]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# (1, 4, H, W)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sample\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 34\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(input_sample, target_sample)\u001b[0m\n\u001b[1;32m     31\u001b[0m refined_residuals \u001b[38;5;241m=\u001b[39m model_VAE\u001b[38;5;241m.\u001b[39mdecode(denoised_latent)  \u001b[38;5;66;03m# (1, 4, H, W)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Unet plus refined residuals\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m final_prediction \u001b[38;5;241m=\u001b[39m \u001b[43munet_prediction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrefined_residuals\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munet_prediction\u001b[39m\u001b[38;5;124m'\u001b[39m: unet_prediction,\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_residuals\u001b[39m\u001b[38;5;124m'\u001b[39m: residuals,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_prediction\u001b[39m\u001b[38;5;124m'\u001b[39m: final_prediction\n\u001b[1;32m     43\u001b[0m }\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (370) must match the size of tensor b (740) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "idx = 20\n",
    "input_sample = train_inputs[idx].unsqueeze(0)  # (1, 5, H, W)\n",
    "target_sample = train_targets[idx].unsqueeze(0)  # (1, 4, H, W)\n",
    "\n",
    "results = pipeline(input_sample, target_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa52a84",
   "metadata": {},
   "source": [
    "Denormalisation and plotting  : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497751ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Denorm function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adaecc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{config.DATASETS_TRAINING_DIR}/RhiresD_scaling_params_chronological.json', 'r') as f:\n",
    "    pr_params = json.load(f)\n",
    "with open(f'{config.DATASETS_TRAINING_DIR}/TabsD_scaling_params_chronological.json', 'r') as f:\n",
    "    temp_params = json.load(f)\n",
    "with open(f'{config.DATASETS_TRAINING_DIR}/TminD_scaling_params_chronological.json', 'r') as f:\n",
    "    temp_min_params = json.load(f)\n",
    "with open(f'{config.DATASETS_TRAINING_DIR}/TmaxD_scaling_params_chronological.json', 'r') as f:\n",
    "    temp_max_params = json.load(f)\n",
    "\n",
    "def denorm_pr(x):\n",
    "\n",
    "    return x * (pr_params['max'] - pr_params['min']) + pr_params['min']\n",
    "\n",
    "def denorm_temp(x, params):\n",
    "\n",
    "    return x * params['std'] + params['mean']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c578c3a",
   "metadata": {},
   "source": [
    "denorm and plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586b300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm_plot(results, input_sample, target_sample):    \n",
    "    input_np = input_sample[0, :4].cpu().numpy() #Elevation removed, was not needed for plotting \n",
    "    target_np = target_sample[0].cpu().numpy()\n",
    "    unet_np = results['unet_prediction'][0].cpu().numpy()\n",
    "    final_np = results['final_prediction'][0].cpu().numpy()\n",
    "    residuals_np = results['refined_residuals'][0].cpu().numpy()\n",
    "    \n",
    "    input_denorm = np.empty_like(input_np)\n",
    "    target_denorm = np.empty_like(target_np)\n",
    "    unet_denorm = np.empty_like(unet_np)\n",
    "    final_denorm = np.empty_like(final_np)\n",
    "    residuals_denorm = np.empty_like(residuals_np)\n",
    "    \n",
    "    for i, (var, params) in enumerate([\n",
    "        (\"precip\", pr_params),\n",
    "        (\"temp\", temp_params), \n",
    "        (\"temp_min\", temp_min_params),\n",
    "        (\"temp_max\", temp_max_params)\n",
    "    ]):\n",
    "        if var == \"precip\":\n",
    "            input_denorm[i] = denorm_pr(input_np[i])\n",
    "            target_denorm[i] = denorm_pr(target_np[i])\n",
    "            unet_denorm[i] = denorm_pr(unet_np[i])\n",
    "            final_denorm[i] = denorm_pr(final_np[i])\n",
    "            residuals_denorm[i] = denorm_pr(residuals_np[i])\n",
    "        else:\n",
    "            input_denorm[i] = denorm_temp(input_np[i], params)\n",
    "            target_denorm[i] = denorm_temp(target_np[i], params)\n",
    "            unet_denorm[i] = denorm_temp(unet_np[i], params)\n",
    "            final_denorm[i] = denorm_temp(final_np[i], params)\n",
    "            residuals_denorm[i] = denorm_temp(residuals_np[i], params)\n",
    "\n",
    "    channel_names = [\"Precip\", \"Temp\", \"Min Temp\", \"Max Temp\"]\n",
    "    fig, axes = plt.subplots(4, 5, figsize=(25, 20))\n",
    "    \n",
    "    for i in range(4): #5 samples\n",
    "        # bicubic IP\n",
    "        axes[i, 0].imshow(input_denorm[i], cmap='coolwarm')\n",
    "        axes[i, 0].set_title(f\"Input - {channel_names[i]}\")\n",
    "        \n",
    "        # UNet\n",
    "        axes[i, 1].imshow(unet_denorm[i], cmap='coolwarm')\n",
    "        axes[i, 1].set_title(f\"UNet Mean - {channel_names[i]}\")\n",
    "        \n",
    "        # Refined Residuals\n",
    "        axes[i, 2].imshow(residuals_denorm[i], cmap='RdBu_r')\n",
    "        axes[i, 2].set_title(f\"Refined Residuals - {channel_names[i]}\")\n",
    "        \n",
    "        # Final pred by Adding Unet mean\n",
    "        axes[i, 3].imshow(final_denorm[i], cmap='coolwarm')\n",
    "        axes[i, 3].set_title(f\"Final Prediction - {channel_names[i]}\")\n",
    "        \n",
    "        # ground truth\n",
    "        axes[i, 4].imshow(target_denorm[i], cmap='coolwarm')\n",
    "        axes[i, 4].set_title(f\"Ground Truth - {channel_names[i]}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "denorm_plot(results, input_sample, target_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffscaler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
