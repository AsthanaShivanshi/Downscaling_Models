{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5bf3df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") #Parent \n",
    "sys.path.append(\"../..\") #grandparent\n",
    "import torch\n",
    "from models.components.ldm.denoiser import UNetModel\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import config\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c0913a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.components.unet import DownscalingUnetLightning \n",
    "from models.ae_module import AutoencoderKL\n",
    "from models.components.ae import SimpleConvEncoder, SimpleConvDecoder\n",
    "from models.components.ldm.denoiser.ddim import DDIMSampler\n",
    "from models.ldm_module import LatentDiffusion\n",
    "from DownscalingDataModule import DownscalingDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee737fc",
   "metadata": {},
   "source": [
    "Instantiating UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee86e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_unet = \"trained_ckpts/Training_LDM.models.components.unet.DownscalingUnetLightning_checkpoint.ckpt\"\n",
    "\n",
    "model_UNet = DownscalingUnetLightning(\n",
    "    in_ch=5,  # 4 vars + elevation\n",
    "    out_ch=4,  # 4 output variables\n",
    "    features=[64, 128, 256, 512],\n",
    "    channel_names=[\"precip\", \"temp\", \"temp_min\", \"temp_max\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b8a04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DownscalingUnetLightning(\n",
       "  (unet): DownscalingUnet(\n",
       "    (e1): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (e2): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (e3): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (e4): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (b): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (d1): DecoderBlock(\n",
       "      (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (d2): DecoderBlock(\n",
       "      (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (d3): DecoderBlock(\n",
       "      (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (d4): DecoderBlock(\n",
       "      (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv): DoubleConv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (outputs): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (loss_fn): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet_state_dict = torch.load(ckpt_unet, map_location=\"cpu\")[\"state_dict\"]\n",
    "model_UNet.load_state_dict(unet_state_dict, strict=False)\n",
    "model_UNet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079fbb63",
   "metadata": {},
   "source": [
    "Instantiating VAE for residual encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fcc53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_vae = \"trained_ckpts/Training_LDM.models.ae_module.AutoencoderKL_checkpoint.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34788231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Load checkpoint to see the original configuration\n",
    "checkpoint = torch.load(ckpt_vae, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c25181a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling_Models/.micromamba/envs/diffscaler/lib/python3.9/site-packages/lightning/pytorch/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['unet_regr.e1.conv.conv.0.weight', 'unet_regr.e1.conv.conv.1.weight', 'unet_regr.e1.conv.conv.1.bias', 'unet_regr.e1.conv.conv.1.running_mean', 'unet_regr.e1.conv.conv.1.running_var', 'unet_regr.e1.conv.conv.1.num_batches_tracked', 'unet_regr.e1.conv.conv.3.weight', 'unet_regr.e1.conv.conv.4.weight', 'unet_regr.e1.conv.conv.4.bias', 'unet_regr.e1.conv.conv.4.running_mean', 'unet_regr.e1.conv.conv.4.running_var', 'unet_regr.e1.conv.conv.4.num_batches_tracked', 'unet_regr.e2.conv.conv.0.weight', 'unet_regr.e2.conv.conv.1.weight', 'unet_regr.e2.conv.conv.1.bias', 'unet_regr.e2.conv.conv.1.running_mean', 'unet_regr.e2.conv.conv.1.running_var', 'unet_regr.e2.conv.conv.1.num_batches_tracked', 'unet_regr.e2.conv.conv.3.weight', 'unet_regr.e2.conv.conv.4.weight', 'unet_regr.e2.conv.conv.4.bias', 'unet_regr.e2.conv.conv.4.running_mean', 'unet_regr.e2.conv.conv.4.running_var', 'unet_regr.e2.conv.conv.4.num_batches_tracked', 'unet_regr.e3.conv.conv.0.weight', 'unet_regr.e3.conv.conv.1.weight', 'unet_regr.e3.conv.conv.1.bias', 'unet_regr.e3.conv.conv.1.running_mean', 'unet_regr.e3.conv.conv.1.running_var', 'unet_regr.e3.conv.conv.1.num_batches_tracked', 'unet_regr.e3.conv.conv.3.weight', 'unet_regr.e3.conv.conv.4.weight', 'unet_regr.e3.conv.conv.4.bias', 'unet_regr.e3.conv.conv.4.running_mean', 'unet_regr.e3.conv.conv.4.running_var', 'unet_regr.e3.conv.conv.4.num_batches_tracked', 'unet_regr.e4.conv.conv.0.weight', 'unet_regr.e4.conv.conv.1.weight', 'unet_regr.e4.conv.conv.1.bias', 'unet_regr.e4.conv.conv.1.running_mean', 'unet_regr.e4.conv.conv.1.running_var', 'unet_regr.e4.conv.conv.1.num_batches_tracked', 'unet_regr.e4.conv.conv.3.weight', 'unet_regr.e4.conv.conv.4.weight', 'unet_regr.e4.conv.conv.4.bias', 'unet_regr.e4.conv.conv.4.running_mean', 'unet_regr.e4.conv.conv.4.running_var', 'unet_regr.e4.conv.conv.4.num_batches_tracked', 'unet_regr.b.conv.0.weight', 'unet_regr.b.conv.1.weight', 'unet_regr.b.conv.1.bias', 'unet_regr.b.conv.1.running_mean', 'unet_regr.b.conv.1.running_var', 'unet_regr.b.conv.1.num_batches_tracked', 'unet_regr.b.conv.3.weight', 'unet_regr.b.conv.4.weight', 'unet_regr.b.conv.4.bias', 'unet_regr.b.conv.4.running_mean', 'unet_regr.b.conv.4.running_var', 'unet_regr.b.conv.4.num_batches_tracked', 'unet_regr.d1.up.weight', 'unet_regr.d1.up.bias', 'unet_regr.d1.conv.conv.0.weight', 'unet_regr.d1.conv.conv.1.weight', 'unet_regr.d1.conv.conv.1.bias', 'unet_regr.d1.conv.conv.1.running_mean', 'unet_regr.d1.conv.conv.1.running_var', 'unet_regr.d1.conv.conv.1.num_batches_tracked', 'unet_regr.d1.conv.conv.3.weight', 'unet_regr.d1.conv.conv.4.weight', 'unet_regr.d1.conv.conv.4.bias', 'unet_regr.d1.conv.conv.4.running_mean', 'unet_regr.d1.conv.conv.4.running_var', 'unet_regr.d1.conv.conv.4.num_batches_tracked', 'unet_regr.d2.up.weight', 'unet_regr.d2.up.bias', 'unet_regr.d2.conv.conv.0.weight', 'unet_regr.d2.conv.conv.1.weight', 'unet_regr.d2.conv.conv.1.bias', 'unet_regr.d2.conv.conv.1.running_mean', 'unet_regr.d2.conv.conv.1.running_var', 'unet_regr.d2.conv.conv.1.num_batches_tracked', 'unet_regr.d2.conv.conv.3.weight', 'unet_regr.d2.conv.conv.4.weight', 'unet_regr.d2.conv.conv.4.bias', 'unet_regr.d2.conv.conv.4.running_mean', 'unet_regr.d2.conv.conv.4.running_var', 'unet_regr.d2.conv.conv.4.num_batches_tracked', 'unet_regr.d3.up.weight', 'unet_regr.d3.up.bias', 'unet_regr.d3.conv.conv.0.weight', 'unet_regr.d3.conv.conv.1.weight', 'unet_regr.d3.conv.conv.1.bias', 'unet_regr.d3.conv.conv.1.running_mean', 'unet_regr.d3.conv.conv.1.running_var', 'unet_regr.d3.conv.conv.1.num_batches_tracked', 'unet_regr.d3.conv.conv.3.weight', 'unet_regr.d3.conv.conv.4.weight', 'unet_regr.d3.conv.conv.4.bias', 'unet_regr.d3.conv.conv.4.running_mean', 'unet_regr.d3.conv.conv.4.running_var', 'unet_regr.d3.conv.conv.4.num_batches_tracked', 'unet_regr.d4.up.weight', 'unet_regr.d4.up.bias', 'unet_regr.d4.conv.conv.0.weight', 'unet_regr.d4.conv.conv.1.weight', 'unet_regr.d4.conv.conv.1.bias', 'unet_regr.d4.conv.conv.1.running_mean', 'unet_regr.d4.conv.conv.1.running_var', 'unet_regr.d4.conv.conv.1.num_batches_tracked', 'unet_regr.d4.conv.conv.3.weight', 'unet_regr.d4.conv.conv.4.weight', 'unet_regr.d4.conv.conv.4.bias', 'unet_regr.d4.conv.conv.4.running_mean', 'unet_regr.d4.conv.conv.4.running_var', 'unet_regr.d4.conv.conv.4.num_batches_tracked', 'unet_regr.outputs.weight', 'unet_regr.outputs.bias']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoencoderKL(\n",
       "  (encoder): SimpleConvEncoder(\n",
       "    (net): Sequential(\n",
       "      (0): ResBlock2D(\n",
       "        (proj): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (act1): SiLU()\n",
       "        (act2): SiLU()\n",
       "        (norm1): GroupNorm(1, 4, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "        (sequence): Sequential(\n",
       "          (0): GroupNorm(1, 4, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (4): SiLU()\n",
       "          (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (decoder): SimpleConvDecoder(\n",
       "    (net): Sequential(\n",
       "      (0): ConvTranspose2d(64, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): ResBlock2D(\n",
       "        (proj): Identity()\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (act1): SiLU()\n",
       "        (act2): SiLU()\n",
       "        (norm1): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "        (sequence): Sequential(\n",
       "          (0): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "          (4): SiLU()\n",
       "          (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (to_moments): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (to_decoder): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = SimpleConvEncoder(in_dim=4, levels=1, min_ch=64, ch_mult=1)\n",
    "decoder = SimpleConvDecoder(in_dim=64, levels=1, min_ch=16)  # Changed from levels=2 to levels=1\n",
    "model_VAE = AutoencoderKL.load_from_checkpoint(\n",
    "    ckpt_vae,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    kl_weight=0.01,\n",
    "    strict=False \n",
    ")\n",
    "model_VAE.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409c4be6",
   "metadata": {},
   "source": [
    "Latent denoising "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13c59dc",
   "metadata": {},
   "source": [
    "For denoisign in latent space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44f1c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_ldm = \"trained_ckpts/LDM_checkpoint.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78220863",
   "metadata": {},
   "source": [
    "remapping of keys for overcoming the error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e4073dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'trained_ckpts/LDM_checkpoint.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ldm_ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_ldm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m remapped_ldm_state_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ldm_ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling_Models/.micromamba/envs/diffscaler/lib/python3.9/site-packages/torch/serialization.py:1484\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1482\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1486\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1488\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1489\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling_Models/.micromamba/envs/diffscaler/lib/python3.9/site-packages/torch/serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling_Models/.micromamba/envs/diffscaler/lib/python3.9/site-packages/torch/serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'trained_ckpts/LDM_checkpoint.ckpt'"
     ]
    }
   ],
   "source": [
    "ldm_ckpt = torch.load(ckpt_ldm, map_location=\"cpu\")\n",
    "remapped_ldm_state_dict = {}\n",
    "for k, v in ldm_ckpt[\"state_dict\"].items():\n",
    "    if k.startswith(\"autoencoder.unet_regr.unet.\"):\n",
    "        new_key = \"autoencoder.unet.\" + k[len(\"autoencoder.unet_regr.unet.\"):]\n",
    "    elif k.startswith(\"autoencoder.unet_regr.\"):\n",
    "        new_key = \"autoencoder.unet.\" + k[len(\"autoencoder.unet_regr.\"):]\n",
    "    else:\n",
    "        new_key = k\n",
    "    remapped_ldm_state_dict[new_key] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3eddcfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser=UNetModel(in_channels=32,\n",
    "  out_channels=32,\n",
    "  model_channels=64,\n",
    "  num_res_blocks=2,\n",
    "  attention_resolutions=[1,2,4],\n",
    "  context_ch=None,  # [128,128,128,128] #Changed to null for a first experiment (unconditional generation from latent space): AsthanaSh\n",
    "  channel_mult=[1,2,4,4],\n",
    "  conv_resample=True,\n",
    "  dims=2,\n",
    "  use_fp16=False,\n",
    "  num_heads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92abfe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LDM=LatentDiffusion(denoiser=denoiser,\n",
    "  autoencoder=model_VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65a37748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDiffusion(\n",
       "  (denoiser): UNetModel(\n",
       "    (time_embed): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (input_blocks): ModuleList(\n",
       "      (0): TimestepEmbedSequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1-2): 2 x TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (middle_block): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): Identity()\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): Identity()\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): Identity()\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): Identity()\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (output_blocks): ModuleList(\n",
       "      (0-1): 2 x TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Upsample(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3-4): 2 x TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Upsample(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Upsample(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): Identity()\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out): Sequential(\n",
       "      (0): Identity()\n",
       "      (1): SiLU()\n",
       "      (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (autoencoder): AutoencoderKL(\n",
       "    (encoder): SimpleConvEncoder(\n",
       "      (net): Sequential(\n",
       "        (0): ResBlock2D(\n",
       "          (proj): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (conv1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): SiLU()\n",
       "          (act2): SiLU()\n",
       "          (norm1): GroupNorm(1, 4, eps=1e-05, affine=True)\n",
       "          (norm2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (sequence): Sequential(\n",
       "            (0): GroupNorm(1, 4, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "            (4): SiLU()\n",
       "            (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "    )\n",
       "    (decoder): SimpleConvDecoder(\n",
       "      (net): Sequential(\n",
       "        (0): ConvTranspose2d(64, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): ResBlock2D(\n",
       "          (proj): Identity()\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): SiLU()\n",
       "          (act2): SiLU()\n",
       "          (norm1): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "          (norm2): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "          (sequence): Sequential(\n",
       "            (0): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "            (4): SiLU()\n",
       "            (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (3): ResBlock2D(\n",
       "          (proj): Identity()\n",
       "          (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act1): SiLU()\n",
       "          (act2): SiLU()\n",
       "          (norm1): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "          (norm2): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "          (sequence): Sequential(\n",
       "            (0): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "            (4): SiLU()\n",
       "            (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (4): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (to_moments): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (to_decoder): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (denoiser_ema): LitEma()\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LDM.load_state_dict(remapped_ldm_state_dict, strict=False)\n",
    "model_LDM.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65521c83",
   "metadata": {},
   "source": [
    "#Inference goes from Unet----VAE----denosiing within VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78ba5b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(input_sample, target_sample=None):  \n",
    "    with torch.no_grad():\n",
    "        # Mean pred with unet\n",
    "        unet_prediction = model_UNet(input_sample)\n",
    "        \n",
    "        #Residuals for denoising\n",
    "        if target_sample is not None:\n",
    "            residuals = target_sample - unet_prediction\n",
    "        \n",
    "        #VAE encoding\n",
    "        mean, log_var = model_VAE.encode(residuals)\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        latent = mean + eps * std  # (1, 64, H', W')\n",
    "        \n",
    "        #Denoising\n",
    "        sampler = DDIMSampler(model_LDM)\n",
    "        shape = latent.shape[1:]\n",
    "        \n",
    "        denoised_latent, _ = sampler.sample(\n",
    "            S=5, #Can be changed later, checking for debugging now\n",
    "            batch_size=1,\n",
    "            shape=shape,\n",
    "            x_T=latent,  # encoded residual latent\n",
    "            eta=0.2,     # stochasticity\n",
    "            verbose=False,\n",
    "            progbar=True\n",
    "        )\n",
    "        \n",
    "        # Decoding\n",
    "        refined_residuals = model_VAE.decode(denoised_latent)  # (1, 4, H, W)\n",
    "        \n",
    "        # Unet plus refined residuals\n",
    "        final_prediction = unet_prediction + refined_residuals\n",
    "        \n",
    "        return {\n",
    "            'unet_prediction': unet_prediction,\n",
    "            'original_residuals': residuals,\n",
    "            'refined_residuals': refined_residuals,\n",
    "            'final_prediction': final_prediction\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bccb9d3",
   "metadata": {},
   "source": [
    "Datasets for dtaamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2baa0737",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_paths = {\n",
    "    'precip': f'{config.DATASETS_TRAINING_DIR}/RhiresD_input_test_chronological_scaled.nc',\n",
    "    'temp': f'{config.DATASETS_TRAINING_DIR}/TabsD_input_test_chronological_scaled.nc',\n",
    "    'temp_min': f'{config.DATASETS_TRAINING_DIR}/TminD_input_test_chronological_scaled.nc',\n",
    "    'temp_max': f'{config.DATASETS_TRAINING_DIR}/TmaxD_input_test_chronological_scaled.nc'\n",
    "}\n",
    "\n",
    "test_target_paths = {\n",
    "    'precip': f'{config.DATASETS_TRAINING_DIR}/RhiresD_target_test_chronological_scaled.nc',\n",
    "    'temp': f'{config.DATASETS_TRAINING_DIR}/TabsD_target_test_chronological_scaled.nc',\n",
    "    'temp_min': f'{config.DATASETS_TRAINING_DIR}/TminD_target_test_chronological_scaled.nc',\n",
    "    'temp_max': f'{config.DATASETS_TRAINING_DIR}/TmaxD_target_test_chronological_scaled.nc'\n",
    "}\n",
    "\n",
    "elevation_path = f'{config.BASE_DIR}/sasthana/Downscaling/Downscaling_Models/elevation.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c70e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DownscalingDataModule(\n",
    "    train_input={},\n",
    "    train_target={},\n",
    "    test_input=test_input_paths,\n",
    "    test_target=test_target_paths,\n",
    "    elevation=elevation_path,\n",
    "    batch_size=32,\n",
    "    num_workers=4,\n",
    "    preprocessing={\n",
    "        'variables': {\n",
    "            'input': {\n",
    "                'precip': 'RhiresD',\n",
    "                'temp': 'TabsD', \n",
    "                'temp_min': 'TminD',\n",
    "                'temp_max': 'TmaxD'\n",
    "            },\n",
    "            'target': {\n",
    "                'precip': 'RhiresD',\n",
    "                'temp': 'TabsD',\n",
    "                'temp_min': 'TminD', \n",
    "                'temp_max': 'TmaxD'\n",
    "            }\n",
    "        },\n",
    "        'preprocessing': {\n",
    "            'nan_to_num': True,\n",
    "            'nan_value': 0.0\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Setup the data module\n",
    "dm.setup('fit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa90a5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 32, 120, 185), eta 0.2\n",
      "Running DDIM Sampling with 5 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 5/5 [05:16<00:00, 63.34s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (370) must match the size of tensor b (740) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m input_sample \u001b[38;5;241m=\u001b[39m test_inputs[idx]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# (1, 5, H, W)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m target_sample \u001b[38;5;241m=\u001b[39m test_targets[idx]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# (1, 4, H, W)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sample\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 34\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(input_sample, target_sample)\u001b[0m\n\u001b[1;32m     31\u001b[0m refined_residuals \u001b[38;5;241m=\u001b[39m model_VAE\u001b[38;5;241m.\u001b[39mdecode(denoised_latent)  \u001b[38;5;66;03m# (1, 4, H, W)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Unet plus refined residuals\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m final_prediction \u001b[38;5;241m=\u001b[39m \u001b[43munet_prediction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrefined_residuals\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munet_prediction\u001b[39m\u001b[38;5;124m'\u001b[39m: unet_prediction,\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_residuals\u001b[39m\u001b[38;5;124m'\u001b[39m: residuals,\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefined_residuals\u001b[39m\u001b[38;5;124m'\u001b[39m: refined_residuals,\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_prediction\u001b[39m\u001b[38;5;124m'\u001b[39m: final_prediction\n\u001b[1;32m     41\u001b[0m }\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (370) must match the size of tensor b (740) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "test_loader = dm.test_dataloader()\n",
    "test_batch = next(iter(test_loader))\n",
    "test_inputs, test_targets = test_batch\n",
    "\n",
    "idx = 20\n",
    "input_sample = test_inputs[idx].unsqueeze(0)  # (1, 5, H, W)\n",
    "target_sample = test_targets[idx].unsqueeze(0)  # (1, 4, H, W)\n",
    "\n",
    "results = pipeline(input_sample, target_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa52a84",
   "metadata": {},
   "source": [
    "Denormalisation and plotting  : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "497751ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Denorm function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adaecc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{config.DATASETS_TRAINING_DIR}/RhiresD_scaling_params_chronological.json', 'r') as f:\n",
    "    pr_params = json.load(f)\n",
    "with open(f'{config.DATASETS_TRAINING_DIR}/TabsD_scaling_params_chronological.json', 'r') as f:\n",
    "    temp_params = json.load(f)\n",
    "with open(f'{config.DATASETS_TRAINING_DIR}/TminD_scaling_params_chronological.json', 'r') as f:\n",
    "    temp_min_params = json.load(f)\n",
    "with open(f'{config.DATASETS_TRAINING_DIR}/TmaxD_scaling_params_chronological.json', 'r') as f:\n",
    "    temp_max_params = json.load(f)\n",
    "\n",
    "def denorm_pr(x):\n",
    "\n",
    "    return x * (pr_params['max'] - pr_params['min']) + pr_params['min']\n",
    "\n",
    "def denorm_temp(x, params):\n",
    "\n",
    "    return x * params['std'] + params['mean']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c578c3a",
   "metadata": {},
   "source": [
    "denorm and plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586b300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm_plot(results, input_sample, target_sample):    \n",
    "    input_np = input_sample[0, :4].cpu().numpy() #Elevation removed, was not needed for plotting \n",
    "    target_np = target_sample[0].cpu().numpy()\n",
    "    unet_np = results['unet_prediction'][0].cpu().numpy()\n",
    "    final_np = results['final_prediction'][0].cpu().numpy()\n",
    "    residuals_np = results['refined_residuals'][0].cpu().numpy()\n",
    "    \n",
    "    input_denorm = np.empty_like(input_np)\n",
    "    target_denorm = np.empty_like(target_np)\n",
    "    unet_denorm = np.empty_like(unet_np)\n",
    "    final_denorm = np.empty_like(final_np)\n",
    "    residuals_denorm = np.empty_like(residuals_np)\n",
    "    \n",
    "    for i, (var, params) in enumerate([\n",
    "        (\"precip\", pr_params),\n",
    "        (\"temp\", temp_params), \n",
    "        (\"temp_min\", temp_min_params),\n",
    "        (\"temp_max\", temp_max_params)\n",
    "    ]):\n",
    "        if var == \"precip\":\n",
    "            input_denorm[i] = denorm_pr(input_np[i])\n",
    "            target_denorm[i] = denorm_pr(target_np[i])\n",
    "            unet_denorm[i] = denorm_pr(unet_np[i])\n",
    "            final_denorm[i] = denorm_pr(final_np[i])\n",
    "            residuals_denorm[i] = denorm_pr(residuals_np[i])\n",
    "        else:\n",
    "            input_denorm[i] = denorm_temp(input_np[i], params)\n",
    "            target_denorm[i] = denorm_temp(target_np[i], params)\n",
    "            unet_denorm[i] = denorm_temp(unet_np[i], params)\n",
    "            final_denorm[i] = denorm_temp(final_np[i], params)\n",
    "            residuals_denorm[i] = denorm_temp(residuals_np[i], params)\n",
    "\n",
    "    channel_names = [\"Precip\", \"Temp\", \"Min Temp\", \"Max Temp\"]\n",
    "    fig, axes = plt.subplots(4, 5, figsize=(25, 20))\n",
    "    \n",
    "    for i in range(4): #5 samples\n",
    "        # bicubic IP\n",
    "        axes[i, 0].imshow(input_denorm[i], cmap='coolwarm')\n",
    "        axes[i, 0].set_title(f\"Input - {channel_names[i]}\")\n",
    "        \n",
    "        # UNet\n",
    "        axes[i, 1].imshow(unet_denorm[i], cmap='coolwarm')\n",
    "        axes[i, 1].set_title(f\"UNet Mean - {channel_names[i]}\")\n",
    "        \n",
    "        # Refined Residuals\n",
    "        axes[i, 2].imshow(residuals_denorm[i], cmap='RdBu_r')\n",
    "        axes[i, 2].set_title(f\"Refined Residuals - {channel_names[i]}\")\n",
    "        \n",
    "        # Final pred by Adding Unet mean\n",
    "        axes[i, 3].imshow(final_denorm[i], cmap='coolwarm')\n",
    "        axes[i, 3].set_title(f\"Final Prediction - {channel_names[i]}\")\n",
    "        \n",
    "        # ground truth\n",
    "        axes[i, 4].imshow(target_denorm[i], cmap='coolwarm')\n",
    "        axes[i, 4].set_title(f\"Ground Truth - {channel_names[i]}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "denorm_plot(results, input_sample, target_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffscaler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
